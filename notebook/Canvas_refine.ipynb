{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Canvas Module - Refine\n",
        "\n",
        "This notebook demonstrates the utility of the OEA_py class notebook, and speeding up the process of refining/pseudonymizing the Canvas data.\n",
        "\n",
        "The steps outlined below describe how this notebook is used to refine the Canvas module tables:\n",
        "\n",
        "- Set the workspace for where the tables are located. \n",
        "- 1 function is defined and used:\n",
        "   1. **refine_canvas**: almost identical to the ```oea.refine()``` function, except removes the assumption that the primary key column is hashed.\n",
        "   2. **refine_canvas_dataset**: uses the Canvas metadata.csv to pseudonymize each table according to whether it is to be hashed, masked, or has no-operation."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workspace = 'dev'\n",
        "version = '2.0'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run OEA_py"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) set the workspace (this determines where in the data lake you'll be writing to and reading from).\n",
        "# You can work in 'dev', 'prod', or a sandbox with any name you choose.\n",
        "# For example, Sam the developer can create a 'sam' workspace and expect to find his datasets in the data lake under oea/sandboxes/sam\n",
        "oea.set_workspace(workspace)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) this step refines the data through the use of metadata (this is where the pseudonymization of the data occurs).\n",
        "def refine_canvas(entity_path, metadata=None, primary_key='id'):\n",
        "    source_path = f'stage2/Ingested/{entity_path}'\n",
        "    primary_key = oea.fix_column_name(primary_key) # fix the column name, in case it has a space in it or some other invalid character\n",
        "    path_dict = oea.parse_path(source_path)\n",
        "    sink_general_path = path_dict['entity_parent_path'].replace('Ingested', 'Refined') + '/general/' + path_dict['entity']\n",
        "    sink_sensitive_path = path_dict['entity_parent_path'].replace('Ingested', 'Refined') + '/sensitive/' + path_dict['entity'] + '_lookup'\n",
        "    if not metadata:\n",
        "        all_metadata = oea.get_metadata_from_path(path_dict['entity_parent_path'])\n",
        "        metadata = all_metadata[path_dict['entity']]\n",
        "\n",
        "    df_changes = oea.get_latest_changes(source_path, sink_general_path)\n",
        "    spark_schema = oea.to_spark_schema(metadata)\n",
        "    df_changes = oea.modify_schema(df_changes, spark_schema)        \n",
        "\n",
        "    if df_changes.count() > 0:\n",
        "        df_pseudo, df_lookup = oea.pseudonymize(df_changes, metadata)\n",
        "        oea.upsert(df_pseudo, sink_general_path, primary_key) # todo: remove this assumption that the primary key will always be hashed during pseduonymization\n",
        "        oea.upsert(df_lookup, sink_sensitive_path, primary_key)    \n",
        "        oea.add_to_lake_db(sink_general_path)\n",
        "        oea.add_to_lake_db(sink_sensitive_path)\n",
        "        logger.info(f'Processed {df_changes.count()} updated rows from {source_path} into stage2/Refined')\n",
        "    else:\n",
        "        logger.info(f'No updated rows in {source_path} to process.')\n",
        "    return df_changes.count()\n",
        "\n",
        "def refine_canvas_dataset(tables_source):\n",
        "    items = oea.get_folders(tables_source)\n",
        "    for item in items: \n",
        "        table_path = tables_source +'/'+ item\n",
        "        if item == 'metadata.csv':\n",
        "            logger.info('ignore metadata processing, since this is not a table to be ingested')\n",
        "        else:\n",
        "            try:\n",
        "                if item == 'accounts':\n",
        "                    refine_canvas('canvas/v2.0/accounts', metadata[item], 'id_pseudonym')\n",
        "                if item == 'content_tags':\n",
        "                    refine_canvas('canvas/v2.0/content_tags', metadata[item], 'content_id')\n",
        "                elif item == 'users':\n",
        "                    refine_canvas('canvas/v2.0/users', metadata[item], 'id_pseudonym')\n",
        "                else:\n",
        "                    refine_canvas('canvas/v2.0/' + item, metadata[item], 'id')\n",
        "            except AnalysisException as e:\n",
        "                # This means the table may have not been properly refined due to errors with the primary key not aligning with columns expected in the lookup table.\n",
        "                pass\n",
        "            \n",
        "            logger.info('Refined table: ' + item + ' from: ' + table_path)\n",
        "    logger.info('Finished refining Canvas tables')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = oea.get_metadata_from_url('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/metadata_v2.csv')\n",
        "refine_canvas_dataset(f'stage2/Ingested/canvas/v{version}')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# non-hashed primary keys are not automatically added to the lake db - add these tables\r\n",
        "oea.add_to_lake_db(f'stage2/Refined/canvas/v{version}/general/assignments')\r\n",
        "oea.add_to_lake_db(f'stage2/Refined/canvas/v{version}/general/content_tags')\r\n",
        "oea.add_to_lake_db(f'stage2/Refined/canvas/v{version}/general/context_modules')\r\n",
        "oea.add_to_lake_db(f'stage2/Refined/canvas/v{version}/general/courses')\r\n",
        "oea.add_to_lake_db(f'stage2/Refined/canvas/v{version}/general/course_sections')\r\n",
        "oea.add_to_lake_db(f'stage2/Refined/canvas/v{version}/general/enrollments')\r\n",
        "oea.add_to_lake_db(f'stage2/Refined/canvas/v{version}/general/enrollment_terms')\r\n",
        "oea.add_to_lake_db(f'stage2/Refined/canvas/v{version}/general/quizzes')\r\n",
        "oea.add_to_lake_db(f'stage2/Refined/canvas/v{version}/general/quiz_submissions')\r\n",
        "oea.add_to_lake_db(f'stage2/Refined/canvas/v{version}/general/roles')\r\n",
        "oea.add_to_lake_db(f'stage2/Refined/canvas/v{version}/general/submissions')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}